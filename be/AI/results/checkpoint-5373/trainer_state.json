{
  "best_global_step": 5373,
  "best_metric": 0.9114321608040201,
  "best_model_checkpoint": "./results\\checkpoint-5373",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 5373,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.027917364600781685,
      "grad_norm": 18.6030216217041,
      "learning_rate": 4.954401637818724e-05,
      "loss": 2.609,
      "step": 50
    },
    {
      "epoch": 0.05583472920156337,
      "grad_norm": 14.876612663269043,
      "learning_rate": 4.90787269681742e-05,
      "loss": 1.9309,
      "step": 100
    },
    {
      "epoch": 0.08375209380234507,
      "grad_norm": 16.186880111694336,
      "learning_rate": 4.861343755816118e-05,
      "loss": 1.5258,
      "step": 150
    },
    {
      "epoch": 0.11166945840312674,
      "grad_norm": 11.340007781982422,
      "learning_rate": 4.814814814814815e-05,
      "loss": 1.1495,
      "step": 200
    },
    {
      "epoch": 0.13958682300390843,
      "grad_norm": 12.122303009033203,
      "learning_rate": 4.768285873813512e-05,
      "loss": 0.9456,
      "step": 250
    },
    {
      "epoch": 0.16750418760469013,
      "grad_norm": 8.807433128356934,
      "learning_rate": 4.7217569328122094e-05,
      "loss": 0.7832,
      "step": 300
    },
    {
      "epoch": 0.1954215522054718,
      "grad_norm": 9.279841423034668,
      "learning_rate": 4.6752279918109066e-05,
      "loss": 0.7024,
      "step": 350
    },
    {
      "epoch": 0.22333891680625348,
      "grad_norm": 12.695013046264648,
      "learning_rate": 4.628699050809604e-05,
      "loss": 0.6175,
      "step": 400
    },
    {
      "epoch": 0.25125628140703515,
      "grad_norm": 10.249034881591797,
      "learning_rate": 4.582170109808301e-05,
      "loss": 0.5033,
      "step": 450
    },
    {
      "epoch": 0.27917364600781686,
      "grad_norm": 9.910784721374512,
      "learning_rate": 4.5356411688069984e-05,
      "loss": 0.5065,
      "step": 500
    },
    {
      "epoch": 0.30709101060859856,
      "grad_norm": 12.133766174316406,
      "learning_rate": 4.489112227805695e-05,
      "loss": 0.4058,
      "step": 550
    },
    {
      "epoch": 0.33500837520938026,
      "grad_norm": 2.3607754707336426,
      "learning_rate": 4.442583286804392e-05,
      "loss": 0.3432,
      "step": 600
    },
    {
      "epoch": 0.3629257398101619,
      "grad_norm": 12.011704444885254,
      "learning_rate": 4.3960543458030896e-05,
      "loss": 0.3811,
      "step": 650
    },
    {
      "epoch": 0.3908431044109436,
      "grad_norm": 9.058038711547852,
      "learning_rate": 4.349525404801787e-05,
      "loss": 0.4472,
      "step": 700
    },
    {
      "epoch": 0.4187604690117253,
      "grad_norm": 20.92755699157715,
      "learning_rate": 4.302996463800484e-05,
      "loss": 0.3678,
      "step": 750
    },
    {
      "epoch": 0.44667783361250696,
      "grad_norm": 8.088776588439941,
      "learning_rate": 4.2564675227991814e-05,
      "loss": 0.3183,
      "step": 800
    },
    {
      "epoch": 0.47459519821328866,
      "grad_norm": 8.251643180847168,
      "learning_rate": 4.2099385817978787e-05,
      "loss": 0.3067,
      "step": 850
    },
    {
      "epoch": 0.5025125628140703,
      "grad_norm": 4.770434379577637,
      "learning_rate": 4.163409640796575e-05,
      "loss": 0.3204,
      "step": 900
    },
    {
      "epoch": 0.5304299274148521,
      "grad_norm": 13.061318397521973,
      "learning_rate": 4.116880699795273e-05,
      "loss": 0.2977,
      "step": 950
    },
    {
      "epoch": 0.5583472920156337,
      "grad_norm": 8.875391960144043,
      "learning_rate": 4.07035175879397e-05,
      "loss": 0.2877,
      "step": 1000
    },
    {
      "epoch": 0.5862646566164154,
      "grad_norm": 12.717571258544922,
      "learning_rate": 4.023822817792667e-05,
      "loss": 0.2153,
      "step": 1050
    },
    {
      "epoch": 0.6141820212171971,
      "grad_norm": 8.793440818786621,
      "learning_rate": 3.977293876791364e-05,
      "loss": 0.274,
      "step": 1100
    },
    {
      "epoch": 0.6420993858179788,
      "grad_norm": 6.286678791046143,
      "learning_rate": 3.9307649357900616e-05,
      "loss": 0.2551,
      "step": 1150
    },
    {
      "epoch": 0.6700167504187605,
      "grad_norm": 12.779094696044922,
      "learning_rate": 3.884235994788759e-05,
      "loss": 0.2942,
      "step": 1200
    },
    {
      "epoch": 0.6979341150195422,
      "grad_norm": 3.941032648086548,
      "learning_rate": 3.837707053787456e-05,
      "loss": 0.1904,
      "step": 1250
    },
    {
      "epoch": 0.7258514796203238,
      "grad_norm": 1.3008800745010376,
      "learning_rate": 3.7911781127861534e-05,
      "loss": 0.2138,
      "step": 1300
    },
    {
      "epoch": 0.7537688442211056,
      "grad_norm": 1.8578259944915771,
      "learning_rate": 3.74464917178485e-05,
      "loss": 0.177,
      "step": 1350
    },
    {
      "epoch": 0.7816862088218872,
      "grad_norm": 0.4212893843650818,
      "learning_rate": 3.698120230783548e-05,
      "loss": 0.1926,
      "step": 1400
    },
    {
      "epoch": 0.8096035734226689,
      "grad_norm": 5.580728054046631,
      "learning_rate": 3.6515912897822445e-05,
      "loss": 0.248,
      "step": 1450
    },
    {
      "epoch": 0.8375209380234506,
      "grad_norm": 7.482842445373535,
      "learning_rate": 3.605062348780942e-05,
      "loss": 0.1904,
      "step": 1500
    },
    {
      "epoch": 0.8654383026242323,
      "grad_norm": 6.281980037689209,
      "learning_rate": 3.558533407779639e-05,
      "loss": 0.1614,
      "step": 1550
    },
    {
      "epoch": 0.8933556672250139,
      "grad_norm": 6.160826683044434,
      "learning_rate": 3.5120044667783364e-05,
      "loss": 0.2567,
      "step": 1600
    },
    {
      "epoch": 0.9212730318257957,
      "grad_norm": 6.349048614501953,
      "learning_rate": 3.465475525777033e-05,
      "loss": 0.1499,
      "step": 1650
    },
    {
      "epoch": 0.9491903964265773,
      "grad_norm": 5.423571586608887,
      "learning_rate": 3.418946584775731e-05,
      "loss": 0.1136,
      "step": 1700
    },
    {
      "epoch": 0.977107761027359,
      "grad_norm": 6.001560688018799,
      "learning_rate": 3.3724176437744275e-05,
      "loss": 0.1704,
      "step": 1750
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8360552763819096,
      "eval_loss": 0.5745248198509216,
      "eval_runtime": 85.6103,
      "eval_samples_per_second": 18.596,
      "eval_steps_per_second": 2.324,
      "step": 1791
    },
    {
      "epoch": 1.0050251256281406,
      "grad_norm": 5.568522930145264,
      "learning_rate": 3.325888702773125e-05,
      "loss": 0.1525,
      "step": 1800
    },
    {
      "epoch": 1.0329424902289224,
      "grad_norm": 6.189526557922363,
      "learning_rate": 3.279359761771823e-05,
      "loss": 0.1708,
      "step": 1850
    },
    {
      "epoch": 1.0608598548297041,
      "grad_norm": 2.245102643966675,
      "learning_rate": 3.232830820770519e-05,
      "loss": 0.1307,
      "step": 1900
    },
    {
      "epoch": 1.0887772194304857,
      "grad_norm": 10.491019248962402,
      "learning_rate": 3.1863018797692166e-05,
      "loss": 0.1373,
      "step": 1950
    },
    {
      "epoch": 1.1166945840312674,
      "grad_norm": 22.55730438232422,
      "learning_rate": 3.139772938767914e-05,
      "loss": 0.1964,
      "step": 2000
    },
    {
      "epoch": 1.1446119486320492,
      "grad_norm": 22.557701110839844,
      "learning_rate": 3.093243997766611e-05,
      "loss": 0.1435,
      "step": 2050
    },
    {
      "epoch": 1.1725293132328307,
      "grad_norm": 14.67078685760498,
      "learning_rate": 3.046715056765308e-05,
      "loss": 0.1359,
      "step": 2100
    },
    {
      "epoch": 1.2004466778336125,
      "grad_norm": 11.226724624633789,
      "learning_rate": 3.0001861157640053e-05,
      "loss": 0.1055,
      "step": 2150
    },
    {
      "epoch": 1.2283640424343942,
      "grad_norm": 2.4779608249664307,
      "learning_rate": 2.9536571747627022e-05,
      "loss": 0.1259,
      "step": 2200
    },
    {
      "epoch": 1.2562814070351758,
      "grad_norm": 4.016990661621094,
      "learning_rate": 2.9071282337614e-05,
      "loss": 0.1267,
      "step": 2250
    },
    {
      "epoch": 1.2841987716359575,
      "grad_norm": 2.4169576168060303,
      "learning_rate": 2.860599292760097e-05,
      "loss": 0.1141,
      "step": 2300
    },
    {
      "epoch": 1.3121161362367393,
      "grad_norm": 2.9788711071014404,
      "learning_rate": 2.814070351758794e-05,
      "loss": 0.1016,
      "step": 2350
    },
    {
      "epoch": 1.3400335008375208,
      "grad_norm": 18.262805938720703,
      "learning_rate": 2.7675414107574917e-05,
      "loss": 0.1347,
      "step": 2400
    },
    {
      "epoch": 1.3679508654383026,
      "grad_norm": 7.667399883270264,
      "learning_rate": 2.7210124697561883e-05,
      "loss": 0.1787,
      "step": 2450
    },
    {
      "epoch": 1.3958682300390843,
      "grad_norm": 15.510998725891113,
      "learning_rate": 2.674483528754886e-05,
      "loss": 0.1225,
      "step": 2500
    },
    {
      "epoch": 1.4237855946398659,
      "grad_norm": 0.2438168227672577,
      "learning_rate": 2.6279545877535828e-05,
      "loss": 0.0938,
      "step": 2550
    },
    {
      "epoch": 1.4517029592406476,
      "grad_norm": 0.16777817904949188,
      "learning_rate": 2.58142564675228e-05,
      "loss": 0.1038,
      "step": 2600
    },
    {
      "epoch": 1.4796203238414294,
      "grad_norm": 0.20365607738494873,
      "learning_rate": 2.534896705750977e-05,
      "loss": 0.0935,
      "step": 2650
    },
    {
      "epoch": 1.507537688442211,
      "grad_norm": 5.7522125244140625,
      "learning_rate": 2.4883677647496746e-05,
      "loss": 0.122,
      "step": 2700
    },
    {
      "epoch": 1.535455053042993,
      "grad_norm": 21.249221801757812,
      "learning_rate": 2.4418388237483715e-05,
      "loss": 0.1235,
      "step": 2750
    },
    {
      "epoch": 1.5633724176437744,
      "grad_norm": 0.34366557002067566,
      "learning_rate": 2.3953098827470688e-05,
      "loss": 0.144,
      "step": 2800
    },
    {
      "epoch": 1.591289782244556,
      "grad_norm": 3.347446918487549,
      "learning_rate": 2.348780941745766e-05,
      "loss": 0.0877,
      "step": 2850
    },
    {
      "epoch": 1.619207146845338,
      "grad_norm": 4.931467533111572,
      "learning_rate": 2.302252000744463e-05,
      "loss": 0.1431,
      "step": 2900
    },
    {
      "epoch": 1.6471245114461195,
      "grad_norm": 0.13400791585445404,
      "learning_rate": 2.2557230597431603e-05,
      "loss": 0.1,
      "step": 2950
    },
    {
      "epoch": 1.675041876046901,
      "grad_norm": 2.4272916316986084,
      "learning_rate": 2.2091941187418576e-05,
      "loss": 0.1004,
      "step": 3000
    },
    {
      "epoch": 1.702959240647683,
      "grad_norm": 1.917559027671814,
      "learning_rate": 2.1626651777405545e-05,
      "loss": 0.1306,
      "step": 3050
    },
    {
      "epoch": 1.7308766052484645,
      "grad_norm": 3.8348989486694336,
      "learning_rate": 2.116136236739252e-05,
      "loss": 0.144,
      "step": 3100
    },
    {
      "epoch": 1.758793969849246,
      "grad_norm": 4.558640003204346,
      "learning_rate": 2.0696072957379494e-05,
      "loss": 0.1679,
      "step": 3150
    },
    {
      "epoch": 1.786711334450028,
      "grad_norm": 0.14202910661697388,
      "learning_rate": 2.0230783547366463e-05,
      "loss": 0.1314,
      "step": 3200
    },
    {
      "epoch": 1.8146286990508096,
      "grad_norm": 0.21572524309158325,
      "learning_rate": 1.9765494137353436e-05,
      "loss": 0.0967,
      "step": 3250
    },
    {
      "epoch": 1.8425460636515911,
      "grad_norm": 15.278180122375488,
      "learning_rate": 1.930020472734041e-05,
      "loss": 0.1425,
      "step": 3300
    },
    {
      "epoch": 1.870463428252373,
      "grad_norm": 13.467839241027832,
      "learning_rate": 1.8834915317327378e-05,
      "loss": 0.1021,
      "step": 3350
    },
    {
      "epoch": 1.8983807928531546,
      "grad_norm": 0.3808033764362335,
      "learning_rate": 1.836962590731435e-05,
      "loss": 0.0965,
      "step": 3400
    },
    {
      "epoch": 1.9262981574539364,
      "grad_norm": 14.731115341186523,
      "learning_rate": 1.7904336497301323e-05,
      "loss": 0.0917,
      "step": 3450
    },
    {
      "epoch": 1.9542155220547182,
      "grad_norm": 3.2136013507843018,
      "learning_rate": 1.7439047087288292e-05,
      "loss": 0.0679,
      "step": 3500
    },
    {
      "epoch": 1.9821328866554997,
      "grad_norm": 1.2985268831253052,
      "learning_rate": 1.6973757677275265e-05,
      "loss": 0.0437,
      "step": 3550
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8894472361809045,
      "eval_loss": 0.35001280903816223,
      "eval_runtime": 35.3306,
      "eval_samples_per_second": 45.06,
      "eval_steps_per_second": 5.633,
      "step": 3582
    },
    {
      "epoch": 2.0100502512562812,
      "grad_norm": 0.2811743915081024,
      "learning_rate": 1.6508468267262238e-05,
      "loss": 0.1157,
      "step": 3600
    },
    {
      "epoch": 2.037967615857063,
      "grad_norm": 0.34524574875831604,
      "learning_rate": 1.604317885724921e-05,
      "loss": 0.1455,
      "step": 3650
    },
    {
      "epoch": 2.0658849804578447,
      "grad_norm": 2.1881704330444336,
      "learning_rate": 1.5577889447236183e-05,
      "loss": 0.0709,
      "step": 3700
    },
    {
      "epoch": 2.0938023450586263,
      "grad_norm": 0.13370642066001892,
      "learning_rate": 1.5112600037223154e-05,
      "loss": 0.0759,
      "step": 3750
    },
    {
      "epoch": 2.1217197096594083,
      "grad_norm": 19.44767951965332,
      "learning_rate": 1.4647310627210125e-05,
      "loss": 0.1041,
      "step": 3800
    },
    {
      "epoch": 2.14963707426019,
      "grad_norm": 13.064595222473145,
      "learning_rate": 1.4182021217197098e-05,
      "loss": 0.0706,
      "step": 3850
    },
    {
      "epoch": 2.1775544388609713,
      "grad_norm": 7.250953197479248,
      "learning_rate": 1.3716731807184069e-05,
      "loss": 0.1416,
      "step": 3900
    },
    {
      "epoch": 2.2054718034617533,
      "grad_norm": 20.15045166015625,
      "learning_rate": 1.325144239717104e-05,
      "loss": 0.1107,
      "step": 3950
    },
    {
      "epoch": 2.233389168062535,
      "grad_norm": 0.07996483147144318,
      "learning_rate": 1.2786152987158013e-05,
      "loss": 0.0599,
      "step": 4000
    },
    {
      "epoch": 2.2613065326633164,
      "grad_norm": 14.527166366577148,
      "learning_rate": 1.2320863577144985e-05,
      "loss": 0.0923,
      "step": 4050
    },
    {
      "epoch": 2.2892238972640984,
      "grad_norm": 18.117496490478516,
      "learning_rate": 1.1855574167131956e-05,
      "loss": 0.0479,
      "step": 4100
    },
    {
      "epoch": 2.31714126186488,
      "grad_norm": 0.16995131969451904,
      "learning_rate": 1.1390284757118929e-05,
      "loss": 0.0385,
      "step": 4150
    },
    {
      "epoch": 2.3450586264656614,
      "grad_norm": 1.210307002067566,
      "learning_rate": 1.09249953471059e-05,
      "loss": 0.1175,
      "step": 4200
    },
    {
      "epoch": 2.3729759910664434,
      "grad_norm": 1.090348720550537,
      "learning_rate": 1.0459705937092873e-05,
      "loss": 0.0893,
      "step": 4250
    },
    {
      "epoch": 2.400893355667225,
      "grad_norm": 0.20360741019248962,
      "learning_rate": 9.994416527079844e-06,
      "loss": 0.0416,
      "step": 4300
    },
    {
      "epoch": 2.4288107202680065,
      "grad_norm": 20.313709259033203,
      "learning_rate": 9.529127117066816e-06,
      "loss": 0.1446,
      "step": 4350
    },
    {
      "epoch": 2.4567280848687885,
      "grad_norm": 0.03237580880522728,
      "learning_rate": 9.063837707053787e-06,
      "loss": 0.0549,
      "step": 4400
    },
    {
      "epoch": 2.48464544946957,
      "grad_norm": 0.08039560168981552,
      "learning_rate": 8.59854829704076e-06,
      "loss": 0.1058,
      "step": 4450
    },
    {
      "epoch": 2.5125628140703515,
      "grad_norm": 0.19345936179161072,
      "learning_rate": 8.133258887027731e-06,
      "loss": 0.1017,
      "step": 4500
    },
    {
      "epoch": 2.5404801786711335,
      "grad_norm": 0.1479148119688034,
      "learning_rate": 7.667969477014704e-06,
      "loss": 0.0429,
      "step": 4550
    },
    {
      "epoch": 2.568397543271915,
      "grad_norm": 0.14256404340267181,
      "learning_rate": 7.202680067001676e-06,
      "loss": 0.1506,
      "step": 4600
    },
    {
      "epoch": 2.5963149078726966,
      "grad_norm": 0.5718381404876709,
      "learning_rate": 6.737390656988648e-06,
      "loss": 0.0616,
      "step": 4650
    },
    {
      "epoch": 2.6242322724734786,
      "grad_norm": 3.133662462234497,
      "learning_rate": 6.272101246975619e-06,
      "loss": 0.0736,
      "step": 4700
    },
    {
      "epoch": 2.65214963707426,
      "grad_norm": 0.14228761196136475,
      "learning_rate": 5.806811836962591e-06,
      "loss": 0.0713,
      "step": 4750
    },
    {
      "epoch": 2.6800670016750416,
      "grad_norm": 1.670650601387024,
      "learning_rate": 5.341522426949562e-06,
      "loss": 0.0611,
      "step": 4800
    },
    {
      "epoch": 2.7079843662758236,
      "grad_norm": 0.44664445519447327,
      "learning_rate": 4.876233016936535e-06,
      "loss": 0.061,
      "step": 4850
    },
    {
      "epoch": 2.735901730876605,
      "grad_norm": 9.175177574157715,
      "learning_rate": 4.410943606923507e-06,
      "loss": 0.0994,
      "step": 4900
    },
    {
      "epoch": 2.7638190954773867,
      "grad_norm": 1.4693294763565063,
      "learning_rate": 3.945654196910478e-06,
      "loss": 0.064,
      "step": 4950
    },
    {
      "epoch": 2.7917364600781687,
      "grad_norm": 15.283105850219727,
      "learning_rate": 3.4803647868974506e-06,
      "loss": 0.097,
      "step": 5000
    },
    {
      "epoch": 2.81965382467895,
      "grad_norm": 0.05720897763967514,
      "learning_rate": 3.015075376884422e-06,
      "loss": 0.0675,
      "step": 5050
    },
    {
      "epoch": 2.8475711892797317,
      "grad_norm": 2.043179512023926,
      "learning_rate": 2.549785966871394e-06,
      "loss": 0.1312,
      "step": 5100
    },
    {
      "epoch": 2.8754885538805137,
      "grad_norm": 8.762928009033203,
      "learning_rate": 2.084496556858366e-06,
      "loss": 0.1014,
      "step": 5150
    },
    {
      "epoch": 2.9034059184812953,
      "grad_norm": 18.81108283996582,
      "learning_rate": 1.619207146845338e-06,
      "loss": 0.0975,
      "step": 5200
    },
    {
      "epoch": 2.931323283082077,
      "grad_norm": 0.457896888256073,
      "learning_rate": 1.1539177368323099e-06,
      "loss": 0.0852,
      "step": 5250
    },
    {
      "epoch": 2.9592406476828588,
      "grad_norm": 4.592751502990723,
      "learning_rate": 6.886283268192816e-07,
      "loss": 0.1331,
      "step": 5300
    },
    {
      "epoch": 2.9871580122836403,
      "grad_norm": 0.28353017568588257,
      "learning_rate": 2.233389168062535e-07,
      "loss": 0.0706,
      "step": 5350
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9114321608040201,
      "eval_loss": 0.34116965532302856,
      "eval_runtime": 34.8978,
      "eval_samples_per_second": 45.619,
      "eval_steps_per_second": 5.702,
      "step": 5373
    }
  ],
  "logging_steps": 50,
  "max_steps": 5373,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.724908011605811e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
